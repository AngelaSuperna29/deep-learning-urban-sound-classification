# -*- coding: utf-8 -*-
"""Multiclass Audio Classification using DeepLearning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1irWVV9LDn3VXvDy08uvGavgxhcP6gWWX
"""

import kagglehub
chrisfilo_urbansound8k_path = kagglehub.dataset_download('chrisfilo/urbansound8k')

print('Data source import complete.')

import numpy as np
import pandas as pd

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        # print(os.path.join(dirname, filename))
        pass

print('Files are ready to use...')

pip install soundfile librosa

# Commented out IPython magic to ensure Python compatibility.
import soundfile as sf
import matplotlib.pyplot as plt
from IPython import display
import seaborn as sns
import librosa
import time

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn import metrics

from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten
from tensorflow.keras.callbacks import ModelCheckpoint

# %matplotlib inline

# Print filepath of first file from each folder
for dirname,_,filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
        break

filename = '/kaggle/input/urbansound8k/fold8/74677-0-0-116.wav'
data,sample_rate = librosa.load(filename)
print(data)
print(len(data))
print(sample_rate)

plt.figure(figsize = (10,5))
librosa.display.waveshow(data,sr = sample_rate)
display.Audio(filename)

metadata = pd.read_csv('/kaggle/input/urbansound8k/UrbanSound8K.csv')
metadata.head()

plt.figure(figsize = (10,8))
sns.countplot(metadata, y="class",order = metadata['class'].value_counts(ascending = False).index )

mfcc_features = librosa.feature.mfcc(y = data, sr = sample_rate, n_mfcc = 50)
mfcc_features.shape

processed_data = []
for i,row in metadata.iterrows():
    filename = os.path.join('/kaggle/input/urbansound8k',f"fold{row['fold']}/{row['slice_file_name']}")
    data,sample_rate = librosa.load(filename)
    mpfcc_features = librosa.feature.mfcc(y = data, sr = sample_rate, n_mfcc = 50)
    mpfcc_features_scaled = np.mean(mpfcc_features.T,axis = 0)
    processed_data.append([mpfcc_features_scaled,row['class']])
    if i%1000 == 0:
        print(f'{i} th iteration out of {metadata.shape[0]} iteration done...')

processed_df = pd.DataFrame(processed_data,columns = ['features','class'])
processed_df.head()

X = np.array(processed_df['features'].tolist())
Y = np.array(processed_df['class'].tolist())

le = LabelEncoder()
y = to_categorical(le.fit_transform(Y))

X.shape

y.shape

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state = 42)
print(f"X_train: {X_train.shape}")
print(f"y_train: {y_train.shape}")
print()
print(f"X_test: {X_test.shape}")
print(f"y_test: {y_test.shape}")

n_inputs = X.shape[1]
n_labels = y.shape[1]

n_1st_layer_neurons = 100
n_2nd_layer_neurons = 200
n_3rd_layer_neurons = 100

### Lets train the a deep learning model

model = Sequential()

## first layer
model.add(Dense(n_1st_layer_neurons,input_shape = (n_inputs,)))
model.add(Activation('relu'))
model.add(Dropout(0.5))

## second layer
model.add(Dense(n_2nd_layer_neurons))
model.add(Activation('relu'))
model.add(Dropout(0.5))

## third layer
model.add(Dense(n_3rd_layer_neurons))
model.add(Activation('relu'))
model.add(Dropout(0.5))

#final layer
model.add(Dense(n_labels))
model.add(Activation('softmax'))

model.summary()

model.compile(loss = 'categorical_crossentropy',metrics = ['accuracy'],optimizer = 'adam')

n_epochs = 100
n_batch_size = 32

checkpointer = ModelCheckpoint(filepath = 'saved_models/audio_classifier.keras',
                              verbose = 1,save_best_only = True)
tic = time.time()

model.fit(X_train,y_train,batch_size = n_batch_size,epochs = n_epochs,
         validation_data = (X_test,y_test),callbacks = [checkpointer])

toc = time.time()

print(f"Model training took {(toc - tic):2f} seconds...")

test_accuracy = model.evaluate(X_test,y_test,verbose = 0)
print(test_accuracy[1])

import librosa
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import load_model
from google.colab import files

# 1. Upload audio file
uploaded = files.upload()

for fn in uploaded.keys():
    file_path = fn
    print(f"Uploaded file: {file_path}")

# 2. Load audio
y, sr = librosa.load(file_path, duration=2.5, offset=0.6)

# 3. Extract features (adjust to match your training setup)
mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=50)
mfcc_scaled = np.mean(mfcc.T, axis=0)

# 4. Reshape for model
mfcc_scaled = mfcc_scaled.reshape(1, -1)

# 5. Load trained model
model = load_model("saved_models/audio_classifier.keras")

prediction = model.predict(mfcc_scaled)
predicted_label = np.argmax(prediction, axis=1)

predicted_class_name = le.inverse_transform(predicted_label)


print("Predicted class:", predicted_class_name)

model.save("audio_model.h5")

import os
os.listdir()

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

import pickle
with open("scaler.pkl", "wb") as f:
    pickle.dump(scaler, f)

from google.colab import files
files.download("scaler.pkl")

import tensorflow as tf
import pickle

model = tf.keras.models.load_model("urbansound_model.h5")
scaler = pickle.load(open("scaler.pkl", "rb"))

print("âœ… Model and scaler loaded successfully!")

import os
os.rename("audio_model.h5", "urbansound_model.h5")
files.download("urbansound_model.h5")
